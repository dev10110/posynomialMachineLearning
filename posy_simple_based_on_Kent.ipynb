{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this implementation employs ideas from\n",
    "# https://people.eecs.berkeley.edu/~nagaban2/resources/portfolio/convex_report.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.418, 0.161, 0.196])"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.872, -1.829, -1.632])"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.log(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.787, 0.835, 0.135, 0.393],\n",
       "        [0.275, 0.923, 0.220, 0.356],\n",
       "        [0.526, 0.985, 0.216, 0.635]], requires_grad=True)"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.rand(3, 4, requires_grad=True)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.860, 0.025, 0.069, 0.203], requires_grad=True)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.rand(4, requires_grad=True)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(1.336, grad_fn=<AddBackward0>),\n",
       " tensor(0.715, grad_fn=<AddBackward0>),\n",
       " tensor(0.203, grad_fn=<AddBackward0>),\n",
       " tensor(0.548, grad_fn=<AddBackward0>)]"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = [torch.matmul(w[:,i], x) + b[i] for i in range(4)]\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(3.804, grad_fn=<ExpBackward>),\n",
       " tensor(2.044, grad_fn=<ExpBackward>),\n",
       " tensor(1.225, grad_fn=<ExpBackward>),\n",
       " tensor(1.731, grad_fn=<ExpBackward>)]"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zh = [torch.exp(zz) for zz in z]\n",
    "zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.804, grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posy = sum(zh)-4\n",
    "posy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.072, -0.565, -2.601,  2.317])"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6*torch.rand(4)-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([], requires_grad=True)"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Parameter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PosyNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(PosyNet, self).__init__()\n",
    "        \n",
    "        # input: 3-vector (x, y, z)\n",
    "        self.len_x = 3\n",
    "        # output: 1-vector, posynomial approximation\n",
    "        \n",
    "        # number of monomials: M\n",
    "        self.M = 9\n",
    "        \n",
    "        \n",
    "        self.w = nn.Parameter(6*torch.rand(self.len_x, self.M)-3)\n",
    "        #self.powers = torch.FloatTensor([[0, -1, 1, 1, 1],[1, -2, 0, 2, 1], [0, -1, 0, 2, 1]]).t()\n",
    "        self.b = nn.Parameter(5*torch.rand(self.M))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        y = torch.log(x)\n",
    "        \n",
    "        z = [torch.log(1+torch.exp(torch.matmul(self.w[:,i], y) + self.b[i])) for i in range(self.M)]\n",
    "        \n",
    "        zh = [torch.exp(zz) for zz in z]\n",
    "        \n",
    "        posy = sum(zh)-self.M\n",
    "           \n",
    "        return posy\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "\n",
    "    out = x[1]**1.5*x[2]**3 + 2*x[0]**2*x[2]**-1 + 3*x[1]**3.2 + 4*x[0]**0.5*x[1]**-2*x[2]\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.412)"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.879])"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PosyNet()\n"
     ]
    }
   ],
   "source": [
    "net = PosyNet()\n",
    "print(net)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.005, momentum=0.9)\n",
    "\n",
    "torch.set_printoptions(precision=3, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-2.846, -0.609, -1.406, -2.838, -2.026, -0.980,  2.593, -1.503, -0.921],\n",
       "         [-1.149, -1.108, -1.907,  2.137, -2.650,  2.437,  0.123,  1.995,  0.226],\n",
       "         [-0.360,  1.448, -2.660,  0.811, -0.082,  2.961, -1.240,  2.773,  0.390]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([3.911, 4.875, 3.333, 4.468, 3.641, 4.055, 2.442, 2.463, 4.062],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_loss_hist = [100]*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100, 100, 100, 100, 100]"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_loss_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(relative_loss_hist[1:] + [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training\n",
      "epoch 0 - loss: 1.31166174, relative loss: 9.44456946, rel loss history: 100.00000000\n",
      "Parameter containing:\n",
      "tensor([[    -0.607,      0.298,     -0.181,     -0.727,     -0.070,     -0.351,\n",
      "              1.793,      0.031,      0.008],\n",
      "        [    -0.311,     -1.034,     -0.859,      0.979,     -1.587,      1.212,\n",
      "              0.601,      2.007,      0.459],\n",
      "        [    -0.251,      0.668,     -0.642,     -0.085,      0.175,      0.975,\n",
      "             -0.478,      1.815,     -0.000]], requires_grad=True)\n",
      "tensor([2.675, 4.789, 2.035, 2.602, 3.133, 2.279, 2.689, 2.192, 4.541],\n",
      "       grad_fn=<ExpBackward>)\n",
      "epoch 1 - loss: 0.14108452, relative loss: 0.28645013, rel loss history: 90.94445695\n",
      "epoch 2 - loss: 0.06908999, relative loss: 0.15881370, rel loss history: 80.97310196\n",
      "epoch 3 - loss: 0.06043557, relative loss: 0.14261970, rel loss history: 70.98898333\n",
      "epoch 4 - loss: 0.05826547, relative loss: 0.13762730, rel loss history: 61.00324530\n",
      "epoch 5 - loss: 0.05588949, relative loss: 0.13236470, rel loss history: 51.01700803\n",
      "epoch 6 - loss: 0.05476548, relative loss: 0.12665791, rel loss history: 41.03024450\n",
      "epoch 7 - loss: 0.05362139, relative loss: 0.12946920, rel loss history: 31.04291029\n",
      "epoch 8 - loss: 0.04409839, relative loss: 0.10489737, rel loss history: 21.05585721\n",
      "epoch 9 - loss: 0.04010723, relative loss: 0.09147184, rel loss history: 11.06634695\n",
      "epoch 10 - loss: 0.03800558, relative loss: 0.08962822, rel loss history: 1.07549413\n",
      "epoch 11 - loss: 0.03490345, relative loss: 0.07692939, rel loss history: 0.14000001\n",
      "epoch 12 - loss: 0.03312328, relative loss: 0.06765851, rel loss history: 0.11904793\n",
      "epoch 13 - loss: 0.03144454, relative loss: 0.06116171, rel loss history: 0.10993241\n",
      "epoch 14 - loss: 0.02980402, relative loss: 0.05420584, rel loss history: 0.10178661\n",
      "epoch 15 - loss: 0.03009203, relative loss: 0.05717360, rel loss history: 0.09344447\n",
      "epoch 16 - loss: 0.02855186, relative loss: 0.04840911, rel loss history: 0.08592536\n",
      "epoch 17 - loss: 0.02779195, relative loss: 0.04465316, rel loss history: 0.07810048\n",
      "epoch 18 - loss: 0.02730772, relative loss: 0.04276920, rel loss history: 0.06961887\n",
      "epoch 19 - loss: 0.02646885, relative loss: 0.03820315, rel loss history: 0.06340606\n",
      "epoch 20 - loss: 0.02579882, relative loss: 0.03576106, rel loss history: 0.05807919\n",
      "epoch 21 - loss: 0.02575214, relative loss: 0.03522064, rel loss history: 0.05269247\n",
      "epoch 22 - loss: 0.02529769, relative loss: 0.03340609, rel loss history: 0.04852160\n",
      "epoch 23 - loss: 0.02528255, relative loss: 0.03494994, rel loss history: 0.04509635\n",
      "epoch 24 - loss: 0.02498802, relative loss: 0.03440953, rel loss history: 0.04247518\n",
      "epoch 25 - loss: 0.02518137, relative loss: 0.03681485, rel loss history: 0.04049555\n",
      "epoch 26 - loss: 0.02417098, relative loss: 0.03044824, rel loss history: 0.03845967\n",
      "epoch 27 - loss: 0.02429212, relative loss: 0.03237084, rel loss history: 0.03666359\n",
      "epoch 28 - loss: 0.02444757, relative loss: 0.03206661, rel loss history: 0.03543535\n",
      "epoch 29 - loss: 0.02383631, relative loss: 0.02984830, rel loss history: 0.03436510\n",
      "epoch 30 - loss: 0.02358465, relative loss: 0.03017948, rel loss history: 0.03352961\n",
      "epoch 31 - loss: 0.02408749, relative loss: 0.03422316, rel loss history: 0.03297145\n",
      "plateau met\n",
      "0.03422315744183531\n",
      "0.03297145213229896\n",
      "epoch 32 - loss: 0.02374995, relative loss: 0.03159887, rel loss history: 0.03287170\n",
      "epoch 33 - loss: 0.02334192, relative loss: 0.03029238, rel loss history: 0.03269098\n",
      "epoch 34 - loss: 0.02307172, relative loss: 0.02925243, rel loss history: 0.03222523\n",
      "epoch 35 - loss: 0.02300772, relative loss: 0.03117393, rel loss history: 0.03170952\n",
      "epoch 36 - loss: 0.02307619, relative loss: 0.03024448, rel loss history: 0.03114542\n",
      "epoch 37 - loss: 0.02356113, relative loss: 0.03353093, rel loss history: 0.03112505\n",
      "epoch 38 - loss: 0.02257978, relative loss: 0.03069123, rel loss history: 0.03124106\n",
      "epoch 39 - loss: 0.02262798, relative loss: 0.02867943, rel loss history: 0.03110352\n",
      "patience met\n",
      "0.02867943334194327\n",
      "0.031103518458499332\n",
      "Parameter containing:\n",
      "tensor([[     0.004,      0.521,      0.059,      0.023,      0.932,      0.004,\n",
      "              2.322,      0.011,      0.004],\n",
      "        [    -0.000,     -2.280,     -0.000,      3.699,     -1.645,      0.579,\n",
      "              0.078,      1.509,     -0.000],\n",
      "        [     0.000,      1.313,     -0.000,     -0.018,      0.001,      0.103,\n",
      "             -0.997,      2.869,      0.000]], requires_grad=True)\n",
      "tensor([0.982, 1.990, 0.995, 1.720, 0.999, 0.996, 1.284, 1.141, 0.995],\n",
      "       grad_fn=<ExpBackward>)\n"
     ]
    }
   ],
   "source": [
    "print('starting training')\n",
    "\n",
    "running_loss = 0\n",
    "relative_loss = 0\n",
    "\n",
    "\n",
    "plateau = 10\n",
    "patience = 10\n",
    "\n",
    "extra_episodes = 2*patience\n",
    "\n",
    "relative_loss_hist = [100]*plateau\n",
    "\n",
    "\n",
    "for epoch in range(1000):\n",
    "    \n",
    "    for data in range(600):\n",
    "    \n",
    "        x = 3*torch.rand(3) + 0.2\n",
    "\n",
    "        y = f(x) + torch.normal(mean=0., std=torch.tensor(0.01*50))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        yh = net(x)\n",
    "\n",
    "        relative_loss += (torch.norm(yh-y)/torch.norm(y)).item()\n",
    "        loss = (torch.log(yh+1) - torch.log(y+1))**2 + 0.001*torch.norm(net.w, p=1) + 0.001*torch.norm(net.b, p=1)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    \n",
    "    \n",
    "    running_loss = running_loss/600\n",
    "    relative_loss = relative_loss/600\n",
    "    \n",
    "    print(f'epoch {epoch} - loss: {running_loss:0.8f}, relative loss: {relative_loss:0.8f}, rel loss history: {(1/plateau)*sum(relative_loss_hist):0.8f}')\n",
    "\n",
    "    \n",
    "    if relative_loss > (1/plateau)*sum(relative_loss_hist) and extra_episodes > patience:\n",
    "        print('plateau met')\n",
    "        print(relative_loss)\n",
    "        print((1/plateau)*sum(relative_loss_hist))\n",
    "        extra_episodes = patience-1\n",
    "    \n",
    "    if extra_episodes < patience:\n",
    "        extra_episodes -= 1\n",
    "    \n",
    "    if extra_episodes == 0:\n",
    "        print('patience met')\n",
    "        print(relative_loss)\n",
    "        print((1/plateau)*sum(relative_loss_hist))\n",
    "        break\n",
    "    \n",
    "    relative_loss_hist = relative_loss_hist[1:] + [relative_loss]\n",
    "    \n",
    "    running_loss = 0\n",
    "    relative_loss = 0\n",
    "    \n",
    "    if epoch%100 == 0:\n",
    "        params = list(net.parameters())\n",
    "        print(params[0])\n",
    "        print(torch.exp(params[1]))\n",
    "        \n",
    "        \n",
    "params = list(net.parameters())\n",
    "print(params[0])\n",
    "print(torch.exp(params[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[     0.010,      0.499,      0.001,      1.967],\n",
       "        [     3.202,     -2.008,      1.470,     -0.000],\n",
       "        [     0.004,      0.984,      3.010,     -0.981]], requires_grad=True)"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.983, 3.980, 1.007, 2.077], grad_fn=<ExpBackward>)"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(params[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[     0.615,     -0.000,      0.010,      1.975],\n",
       "         [    -1.787,     -0.000,      2.743,      0.390],\n",
       "         [     1.178,     -0.001,      0.779,     -1.519]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 1.525, -0.375,  1.565,  0.264], requires_grad=True)]"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.53, -1.81, 0.03, 0.8],\n",
       " [-4.64, -2.39, 1.01, 0.66],\n",
       " [0.59, -0.0, 0.6, -1.38]]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[float(f'{pp:2.2f}') for pp in p] for p in params[0].data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.87, 0.0, 0.7, 0.9]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[float(f'{p:2.2f}') for p in params[1].data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvals = []\n",
    "for _ in range(1000):\n",
    "    x = 3*torch.rand(3) + 0.2\n",
    "    y = f(x).item()\n",
    "    fvals.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_f = pd.DataFrame(fvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>71.740356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>56.237701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.726056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.942504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>54.288652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>97.200777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>327.032196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  1000.000000\n",
       "mean     71.740356\n",
       "std      56.237701\n",
       "min       3.726056\n",
       "25%      31.942504\n",
       "50%      54.288652\n",
       "75%      97.200777\n",
       "max     327.032196"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.2999)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.normal(mean=0.5, std=torch.tensor(0.01*50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = PosyNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 2.9530,  1.4717, -1.9047,  1.0967],\n",
       "         [-0.4320, -0.5977, -1.4674, -1.3579],\n",
       "         [ 2.9908, -0.8913,  2.5368, -2.0302]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([4.4431, 1.0680, 1.9927, 4.4015], requires_grad=True)]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 2.9530,  1.4717, -1.9047,  1.0967],\n",
       "        [-0.4320, -0.5977, -1.4674, -1.3579],\n",
       "        [ 2.9908, -0.8913,  2.5368, -2.0302]], requires_grad=True)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([4.4431, 1.0680, 1.9927, 4.4015], requires_grad=True)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  2.0000,  0.0000,  0.5000],\n",
       "        [ 1.5000,  0.0000,  3.2000, -2.0000],\n",
       "        [ 3.0000, -1.0000,  0.0000,  1.0000]])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[0, 2, 0, 0.5], [1.5, 0, 3.2, -2], [3, -1, 0, 1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "log(): argument 'input' (position 1) must be Tensor, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-284-ab336f2c2233>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: log(): argument 'input' (position 1) must be Tensor, not list"
     ]
    }
   ],
   "source": [
    "torch.log([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([1., 2, 3, 4])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.6931, 1.0986, 1.3863])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PosyNet2(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(PosyNet2, self).__init__()\n",
    "        \n",
    "        # input: 3-vector (x, y, z)\n",
    "        self.len_x = 3\n",
    "        # output: 1-vector, posynomial approximation\n",
    "        \n",
    "        # number of monomials: M\n",
    "        self.M = 4\n",
    "        \n",
    "        \n",
    "        self.w = torch.FloatTensor([[0, 2, 0, 0.5], [1.5, 0, 3.2, -2], [3, -1, 0, 1]])\n",
    "        #self.powers = torch.FloatTensor([[0, -1, 1, 1, 1],[1, -2, 0, 2, 1], [0, -1, 0, 2, 1]]).t()\n",
    "        self.b = torch.log(torch.tensor([1., 2, 3, 4]))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        y = torch.log(x)\n",
    "        \n",
    "        z = [torch.log(1+torch.exp(torch.matmul(self.w[:,i], y) + self.b[i])) for i in range(self.M)]\n",
    "        \n",
    "        zh = [torch.exp(zz) for zz in z]\n",
    "        \n",
    "        posy = sum(zh)-self.M\n",
    "        \n",
    "        return posy\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = PosyNet2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7905, 1.9097, 1.6581])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 3*torch.rand(3)+0.2\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(48.2384)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(48.2384)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
