{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PosyLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self,len_x, M):\n",
    "        \n",
    "        super(PosyLayer, self).__init__()\n",
    "        \n",
    "        self.len_x = len_x\n",
    "        \n",
    "        self.M = M\n",
    "        \n",
    "        self.w = nn.Parameter(6*torch.rand(self.len_x, self.M)-3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        y = torch.log(x)\n",
    "        \n",
    "        z = [torch.log(1+torch.exp(torch.matmul(self.w[:,i], y))) for i in range(self.M)]\n",
    "        \n",
    "        monomial = torch.stack([torch.exp(zz)-1 for zz in z])\n",
    "        \n",
    "        return monomial #which is of length self.M\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class PosyNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(PosyNet, self).__init__()\n",
    "        \n",
    "        # input: 5-vector (state of rocket: x, z, vx, vz, m)\n",
    "        # output: 2-vector (thrust: mag, direction)\n",
    "        \n",
    "        # hidden: 3-posynomial layer\n",
    "        \n",
    "        self.posy = PosyLayer(len_x = 5, M = 3)\n",
    "        \n",
    "        # an affine operation: y = Wx + b\n",
    "        #self.fc = nn.Linear(3, 2)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        m = self.posy(x)\n",
    "        \n",
    "        #out = self.fc(monomials)\n",
    "        \n",
    "        out1 = 2*m[0] - (12/9)*m[1]\n",
    "        out2 = (2-4/3)*m[2]\n",
    "        \n",
    "        return torch.stack([out1, out2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_actual(state):\n",
    "    \n",
    "    x, z, vx, vz, m = state\n",
    "    \n",
    "    tgo = -3*z/vz\n",
    "    \n",
    "    ax = -6*vx/tgo - 12*x/tgo**2\n",
    "    \n",
    "    az = -6*vz/tgo - 12*z/tgo**2\n",
    "    \n",
    "    return torch.stack([ax, m*az])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PosyNet(\n",
      "  (posy): PosyLayer()\n",
      ")\n",
      "[Parameter containing:\n",
      "tensor([[ 1.778,  1.529, -0.505],\n",
      "        [-2.890, -0.394, -1.673],\n",
      "        [-0.253, -1.269, -1.228],\n",
      "        [-2.545,  1.282, -2.293],\n",
      "        [-1.335, -2.077, -2.322]], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "net = PosyNet()\n",
    "print(net)\n",
    "\n",
    "print(list(net.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=5e-9, momentum=0)\n",
    "\n",
    "torch.set_printoptions(precision=3, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-36f2304d15b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloss_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.7417\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11.2250\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m     \"\"\"\n\u001b[0;32m--> 669\u001b[0;31m     \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;31m# catch default case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "loss_list = [0,0,0,0,0]\n",
    "torch.norm(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007456316947937012\n",
      "0.05726411819458008\n",
      "0.993149169921875\n",
      "14.257560546875\n",
      "1.268783447265625\n",
      "0.06069847106933594\n",
      "0.0019337350130081176\n",
      "3.091701171875\n",
      "333.97975\n",
      "0.040431156158447265\n",
      "0.010803759574890137\n",
      "1.1575059814453126\n",
      "1.7184486083984376\n",
      "0.011640181541442871\n",
      "0.011935436248779296\n",
      "0.03442788314819336\n",
      "0.000636514127254486\n",
      "0.0001996240019798279\n",
      "0.04415350341796875\n",
      "0.14709719848632813\n",
      "0.0009865223169326783\n",
      "0.0334168701171875\n",
      "7.36480615234375\n",
      "1.945213134765625\n",
      "2.089565185546875\n",
      "1.0725968017578125\n",
      "5.2891135215759276e-05\n",
      "0.2642780151367187\n",
      "1.816984130859375\n",
      "3.637405029296875\n",
      "2.859822998046875\n",
      "72.9176953125\n",
      "0.014842097282409667\n",
      "0.006103195190429687\n",
      "1.3842847900390625\n",
      "0.024494821548461915\n",
      "1.0879381103515624\n",
      "0.007654178619384766\n",
      "0.480587158203125\n",
      "0.07872679901123047\n",
      "1.103445068359375\n",
      "3.43702783203125\n",
      "1.3836959228515624\n",
      "0.015435029983520508\n",
      "0.24208116149902345\n",
      "0.433352783203125\n",
      "0.009395671844482421\n",
      "1.2020196533203125\n",
      "0.9599261474609375\n",
      "0.06300180435180663\n",
      "75.4420859375\n",
      "0.0009559082984924316\n",
      "2.008388427734375\n",
      "0.012130475997924805\n",
      "244.6818125\n",
      "3.42433935546875\n",
      "0.24678382873535157\n",
      "0.0030371313095092774\n",
      "0.0754599838256836\n",
      "0.03683456039428711\n",
      "1.0519381103515626\n",
      "0.4971133117675781\n",
      "1.4655264892578126\n",
      "18.196474609375\n",
      "0.1120648422241211\n",
      "0.8933861083984375\n",
      "0.06413333892822265\n",
      "0.013555895805358887\n",
      "3.673188720703125\n",
      "0.06413971710205078\n",
      "0.016132415771484374\n",
      "0.03676729202270508\n",
      "0.00019146066904067994\n",
      "0.0714601821899414\n",
      "0.01156008529663086\n",
      "0.39481103515625\n",
      "0.14479434204101563\n",
      "0.0062255702018737796\n",
      "0.13288272094726564\n",
      "0.030533231735229493\n",
      "0.008829864501953125\n",
      "0.0028617324829101564\n",
      "0.03097749900817871\n",
      "0.004781774997711182\n",
      "277.57559375\n",
      "0.0026332101821899415\n",
      "0.0011064096689224242\n",
      "0.668697265625\n",
      "27.257794921875\n",
      "0.46937017822265625\n",
      "4.42040966796875\n",
      "0.00315793514251709\n",
      "0.015864726066589355\n",
      "0.620976318359375\n",
      "0.1572791290283203\n",
      "0.008009172439575196\n",
      "0.004172792911529541\n",
      "0.005073930740356445\n",
      "1.5527965087890625\n",
      "0.015267733573913575\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0\n",
    "for epoch in range(100):\n",
    "\n",
    "    state = 0.2+torch.rand(5)\n",
    "    actual = compute_actual(state)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    net_prediction = net(state)\n",
    "\n",
    "    #loss = 0.5*sum(torch.log(net_prediction**2) - torch.log(actual**2)) + 0.001*torch.norm(net.posy.w, p=1)\n",
    "    loss = criterion(actual, net_prediction)\n",
    "    #loss = torch.log(loss) + 0.001*torch.norm(net.posy.w, p=1)\n",
    "    loss += 0.001*torch.norm(net.posy.w, p=1)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    running_loss += loss.item()\n",
    "    \n",
    "    if epoch%1==0: \n",
    "        print(running_loss/1000)\n",
    "        running_loss = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   36.175,   861.884,    52.206, 141177.516,   482.376],\n",
       "       grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.268, grad_fn=<AddBackward0>)\n",
      "tensor(2.726, grad_fn=<LogBackward>)\n",
      "tensor(0.020, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loss)\n",
    "print(torch.log(loss))\n",
    "print(0.001*torch.norm(net.posy.w, p=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 1.803,  1.529, -0.346],\n",
       "         [-2.016, -0.396, -1.471],\n",
       "         [-0.033, -1.269, -0.969],\n",
       "         [-1.724,  1.281, -1.963],\n",
       "         [-0.967, -2.078, -2.031]], requires_grad=True)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.658, 5.218, 5.974, 5.003, 5.833])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = 5 + torch.rand(5)\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.522, 18.649])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_actual(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    -0.187,      0.000], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vz' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e9e34adb7a1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvz\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtgo\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtgo\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1.6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vz' is not defined"
     ]
    }
   ],
   "source": [
    "az = -6*vz/tgo - 12*z/tgo**2 + 1.6\n",
    "az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack([ax, az])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_actual(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "\n",
    "\n",
    "input = torch.rand(5, requires_grad = True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    actual = compute_actual(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_prediction = net(input)\n",
    "net_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(net_prediction, actual)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.autograd.set_detect_anomaly(True):\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('started training')\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
